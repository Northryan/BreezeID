{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "576de9b4-6f44-460f-adca-27520a94dac5",
   "metadata": {},
   "source": [
    "# Diurnal Breeze Identification Method (BreezeID)\n",
    "\n",
    "This script is designed to detect land and sea breeze events using wind speed and direction data. The data is first transformed into a shore-parallel coordinate system, then filtered and analyzed to identify breeze events based on specific criteria. The script outputs two tables summarizing the characteristics of the detected land and sea breeze events. This script is designed to handle a single NetCDF file as the data import file. A separate script, titled \"BreezeID_csv,\" has been developed to handle CSV files. The script is designed such that only the user-specified parameters need to be changed. A step-by-step guide outlining each of the user-specified parameters is provided in the README file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e060e-2965-4ed7-9cb8-3ca4d32c86d1",
   "metadata": {},
   "source": [
    "## Outline of Script Workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba7900-362d-4562-8d7d-7f042a8adccb",
   "metadata": {},
   "source": [
    "1. User Defined Parameters\n",
    "    * Time Definitions, Detection Windows, Data Range, File Locations, Coastline Shape, Filtering Parameters, Output Parameters\n",
    "<br>\n",
    "<br>\n",
    "2. Library Calls\n",
    "    * Loading necessary libraries\n",
    "<br>\n",
    "<br>\n",
    "3. Function Definitions\n",
    "    * Various functions for calculations, data filtering, and breeze detection\n",
    "<br>\n",
    "<br>\n",
    "4. Variable Creation\n",
    "    * Time variables, day vectors, filtering MJO data\n",
    "<br>\n",
    "<br>\n",
    "5. Data Import\n",
    "    * Reading and combining data files\n",
    "<br>\n",
    "<br>\n",
    "6. Grid Rotation\n",
    "    * Calculating the rotated u and v components of wind\n",
    "<br>\n",
    "<br>\n",
    "7. Filtering Algorithm\n",
    "    * Isolating the diurnal part of the flow\n",
    "<br>\n",
    "<br>\n",
    "8. Detection Algorithm Execution\n",
    "    * Running the event identification criteria\n",
    "<br>\n",
    "<br>\n",
    "9. Data Table Output\n",
    "    * Creating and exporting output tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a9a41-1409-467f-a946-89aa124d6b36",
   "metadata": {},
   "source": [
    "## User-Specified Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547908f-e351-4962-9ff6-c5751eb8e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Time Definitions #####\n",
    "\n",
    "# UTC to Local Time #\n",
    "local_zero_utc = 7                              # Specify what 0 UTC is in local 24-hour time\n",
    "sampling_rate = 1                               # Specify the sampling rate in terms of hours (e.g, 1 for hourly, 0.5 for half-hourly)\n",
    "\n",
    "# Land Breeze Detection 24-Hour Window #\n",
    "land_breeze_window_start_time = 10              # Specify when to start a new land breeze day in local 24-hour time\n",
    "\n",
    "# Sea Breeze Detection 24-Hour Window #\n",
    "sea_breeze_window_start_time = 7                # Specify when to start a new sea breeze day in local 24-hour time\n",
    "\n",
    "# Data Range #\n",
    "data_start_date = \"2018-01-01\"                  # The start date of your data in YYYY-MM-DD\n",
    "data_end_date = \"2018-12-31\"                    # The end date of your data in YYYY-MM-DD\n",
    "\n",
    "##### MJO RMM File #####\n",
    "MJO_RMM_file_location = \"path/to/modified_rmm.74toRealtime.txt\" # Path to folder with MJO information\n",
    "\n",
    "##### Data Files #####\n",
    "data_file_path = \"path/to/data_directory\"       # Path to folder with data files\n",
    "file_type = \"nc\"                                # Currently designed to handle NetCDF files\n",
    "u_comp_name = \"u10\"                             # User-defined variable name for u component wind\n",
    "v_comp_name = \"v10\"                             # User-defined variable name for v component wind\n",
    "\n",
    "lat_interest = -4.0                             # Latitude of analysis coordinate\n",
    "lon_interest = 102.25                           # Longitude of analysis coordinate \n",
    "\n",
    "#####Coastline Shape#####\n",
    "\n",
    "# User-specified rotation angle\n",
    "coordinate_axis_rotation_user = 40.00            # Change to FALSE if using calculated angle\n",
    "\n",
    "# # Latitude and Longitude for three points\n",
    "# lat1 = -4.26  # Point 1 Latitude\n",
    "# lon1 = 102.69 # Point 1 Longitude\n",
    "# lat2 = -3.86  # Point 2 Latitude\n",
    "# lon2 = 102.30 # Point 2 Longitude\n",
    "# lat3 = -3.52  # Point 3 Latitude\n",
    "# lon3 = 102.02 # Point 3 Longitude\n",
    "\n",
    "#####Filtering Parameters#####\n",
    "synoptic_filter_period = 3                      # Defined in days\n",
    "noise_filter_period = 7                         # Defined in hours\n",
    "\n",
    "#####Data Table Output Parameters#####\n",
    "data_table_output_directory = \"path/to/data_output_directory\"       # File path to desired output data directory\n",
    "output_file_name_land = \"land_breeze_output_table.csv\"              # File name for land breeze output table (CSV)\n",
    "output_file_name_sea  = \"sea__breeze_output_table.csv\"              # File name for sea breeze output table (CVS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa036be-dddc-407e-a0bd-b12f48af2641",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f8de7-aad6-4128-b8ea-610b92bf61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ncdf4)     # Provides tools for reading, writing, and manipulating NetCDF files\n",
    "library(dplR)      # Contains functions for filtering and analyzing data\n",
    "library(lubridate) # Facilitates working with dates and times by providing functions for parsing, manipulating, and performing arithmetic on date-time objects\n",
    "library(dplyr)     # Offers a set of tools for data manipulation, including functions for filtering, selecting, and transforming data frames\n",
    "library(zoo)       # Provides infrastructure for working with regular and irregular time series data, including functions for creating, indexing, and merging time series objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a782a-d71b-41a5-892d-5fb1b444b554",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b75de-578e-4483-ad3d-48bd8ba2c31d",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385d2eb-9a98-4b8d-905c-a350304defab",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Calculate the number of days#####\n",
    "calculate_num_days = function(start_date, end_date) {\n",
    "  num_days = as.numeric(difftime(ymd(end_date), ymd(start_date), units = \"days\")) + 1\n",
    "  return(num_days)\n",
    "}\n",
    "\n",
    "#####Create the time vector#####\n",
    "create_time_vector = function(local_0_utc, num_days, sampling_rate) {\n",
    "  if (local_0_utc == 0) {\n",
    "    # Define the time sequence for one day starting from midnight\n",
    "    time_seq = seq(0, 23, by = sampling_rate)\n",
    "  } else {\n",
    "    # Define the time sequence for one day based on the specified local time for 0 UTC\n",
    "    time_seq = c(seq(local_0_utc, 23, by = sampling_rate), seq(0, local_0_utc - sampling_rate, by = sampling_rate))\n",
    "  }\n",
    "  # Replicate the time sequence for the specified number of days\n",
    "  timefile = rep(time_seq, num_days)\n",
    "  return(timefile)\n",
    "}\n",
    "\n",
    "#####Create the days of year table#####\n",
    "create_days_of_year_table = function(start_date, end_date) {\n",
    "  # Generate date range\n",
    "  date_range = seq(ymd(start_date), ymd(end_date), by = \"days\")\n",
    "  \n",
    "  # Create data frame\n",
    "  df = data.frame(\n",
    "    Day_num = 1:length(date_range),\n",
    "    Date = format(date_range, \"%d-%b-%Y\"),\n",
    "    Year = year(date_range),\n",
    "    Month = month(date_range),\n",
    "    Day_of_Month = day(date_range)\n",
    "  )\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "#####Filter MJO data by date range####\n",
    "filter_mjo_data = function(file_path, start_date, end_date) {\n",
    "  # Read the MJO data file\n",
    "  MJO_file = read.table(file_path, header = TRUE)\n",
    "  \n",
    "  # Combine year, month, and day columns to create a date column\n",
    "  MJO_file = MJO_file %>%\n",
    "    mutate(Date = make_date(year, month, day))\n",
    "  \n",
    "  # Filter the data based on the specified date range\n",
    "  filtered_mjo = MJO_file %>%\n",
    "    filter(Date >= as.Date(start_date) & Date <= as.Date(end_date))\n",
    "  \n",
    "  return(filtered_mjo)\n",
    "}\n",
    "\n",
    "#####Land/Sea Breeze Day Vector Definition#####\n",
    "generate_day_vector= function(local_time_at_0_utc, start_counting_hour, sampling_frequency, num_days) {\n",
    "  \n",
    "  crossing_midnight = FALSE\n",
    "  \n",
    "  repeat {\n",
    "    # Adjust start_counting_hour if crossing midnight\n",
    "    if (crossing_midnight) {\n",
    "      start_counting_hour = start_counting_hour + 24\n",
    "    }\n",
    "    \n",
    "    # Calculate the number of observations before the start counting hour\n",
    "    observations_before_start = (start_counting_hour - local_time_at_0_utc) %% 24 / sampling_frequency\n",
    "    \n",
    "    # Initialize the day vector\n",
    "    day_vector = c()\n",
    "    \n",
    "    if (local_time_at_0_utc < start_counting_hour) {\n",
    "      # Use 0s for the observations before the start counting hour\n",
    "      day_vector = rep(0, observations_before_start)\n",
    "      day_vector = c(day_vector, rep(1, 24 / sampling_frequency))\n",
    "    } else if (local_time_at_0_utc == start_counting_hour) {\n",
    "      # Handle the case where local_time_at_0_utc is equal to start_counting_hour\n",
    "      day_vector = rep(1, 24 / sampling_frequency)\n",
    "    } else {\n",
    "      # Start counting from 1 with fewer observations for the first day\n",
    "      observations_for_first_day = 24 - observations_before_start\n",
    "      day_vector = rep(1, 24 - observations_for_first_day)\n",
    "    }\n",
    "    \n",
    "    # Calculate the number of observations per day\n",
    "    observations_per_day = 24 / sampling_frequency\n",
    "    \n",
    "    # Loop through each day of the year starting from the second day\n",
    "    for (i in 2:num_days) {\n",
    "      day_vector = c(day_vector, rep(i, observations_per_day))\n",
    "    }\n",
    "    \n",
    "    # Remove the last few elements to ensure the vector length matches the expected length\n",
    "    expected_length = num_days * observations_per_day\n",
    "    day_vector = day_vector[1:expected_length]\n",
    "    \n",
    "    # Check for NA values\n",
    "    if (any(is.na(day_vector))) {\n",
    "      crossing_midnight = TRUE\n",
    "    } else {\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(day_vector)\n",
    "}\n",
    "\n",
    "#####Zero-Crossing Calculation Function#####\n",
    "zero_crossing=function(time_1,value_t1,time_2,value_t2){\n",
    "  zero_value=(time_1*value_t2-time_2*value_t1)/(value_t2-value_t1)\n",
    "  return(zero_value)\n",
    "}\n",
    "\n",
    "#####Index to Time Function#####\n",
    "convert_index_to_time = function(index, time_file, sampling_frequency) {\n",
    "  # Get the integer part and the fractional part of the index\n",
    "  int_part = floor(index)\n",
    "  frac_part = index - int_part\n",
    "  \n",
    "  # Get the time at the integer part of the index\n",
    "  time_at_int = time_file[int_part]\n",
    "  \n",
    "  # Calculate the interpolated time\n",
    "  interpolated_time = time_at_int + frac_part * sampling_frequency\n",
    "  \n",
    "  # Adjust for wrap-around at 24 hours\n",
    "  if (interpolated_time >= 24) {\n",
    "    interpolated_time = interpolated_time - 24\n",
    "  }\n",
    "  \n",
    "  return(interpolated_time)\n",
    "}\n",
    "\n",
    "#####Rotation Angle Calculation#####\n",
    "calculate_angle_from_x_axis = function(lat1, lon1, lat2, lon2, lat3, lon3) {\n",
    "  # Combine points into a data frame\n",
    "  points = data.frame(\n",
    "    lat = c(lat1, lat2, lat3),\n",
    "    lon = c(lon1, lon2, lon3)\n",
    "  )\n",
    "  \n",
    "  # Fit a linear model\n",
    "  fit = lm(lat ~ lon, data = points)\n",
    "  \n",
    "  # Extract the slope of the best fit line\n",
    "  slope = coef(fit)[2]\n",
    "  \n",
    "  # Calculate the angle from the positive x-axis\n",
    "  angle = atan(slope) * 180 / pi\n",
    "  \n",
    "  # Ensure the angle is defined positive for counterclockwise rotation\n",
    "  if (angle < 0) {\n",
    "    angle = angle + 360\n",
    "  }\n",
    "  \n",
    "  # Angle of rotation to make the positive x-axis perpendicular to the best fit line\n",
    "  angle = angle + 90\n",
    "  \n",
    "  # Ensure the angle is within the range of 0 to 360 degrees\n",
    "  if (angle > 360) {\n",
    "    angle = angle - 360\n",
    "  }\n",
    "  \n",
    "  return(as.numeric(angle))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852cee1c-9523-430c-9c1f-fd1c5ef70697",
   "metadata": {},
   "source": [
    "### Data Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959dd8b-5412-4b0e-adb7-2ef70fd4bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Table Creator Functions: Land#####\n",
    "table_maker_land = function(data_matrix, local_0UTC_time, land_breeze_window_start_time){\n",
    "  event = c(\"Classic\", \"Interruption\")\n",
    "  end = dim(data_matrix)[1]\n",
    "  z = seq(1, end, by = 1)\n",
    "  output_matrix = matrix(nrow = length(z), ncol = 14)\n",
    "  icount = 1\n",
    "  first_go_around = TRUE\n",
    "  date_tracker = list()\n",
    "  \n",
    "  for (num in z){\n",
    "    if (is.na(data_matrix[num, 27]) == TRUE & is.na(data_matrix[num, 37]) == TRUE){\n",
    "    }\n",
    "    if (is.na(data_matrix[num, 32]) == FALSE){\n",
    "      \n",
    "      # Check the day vector #\n",
    "      if (first_go_around) {\n",
    "        if (day_vector_land[num] == 0) {\n",
    "          day_vector_land = day_vector_land + 1\n",
    "          zero_utc_condition = TRUE\n",
    "          first_go_around = FALSE\n",
    "          \n",
    "        } else {\n",
    "          day_vector_land = day_vector_land\n",
    "          zero_utc_condition = FALSE\n",
    "          first_go_around = FALSE\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      ####Interruption Events####\n",
    "      \n",
    "      day_index = which(days_of_year_table[, 1] == day_vector_land[num])\n",
    "      date = paste(days_of_year_table[day_index, 4], days_of_year_table[day_index, 5], days_of_year_table[day_index, 3], sep = \"-\")\n",
    "      \n",
    "      if (date %in% date_tracker) {\n",
    "        \n",
    "        # Check the second duplicate onset time value\n",
    "        if (as.numeric(data_matrix[num, 32]) < land_breeze_window_start_time) {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5] + 1\n",
    "          next_day_index = day_index + 1\n",
    "          output_matrix[icount, 8] = mjo_data[next_day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[next_day_index, 7], digits = 2)\n",
    "          output_matrix[icount, 14] = days_of_year_table[next_day_index, 3]\n",
    "          output_matrix[icount - 1, 14] = days_of_year_table[day_index, 3]\n",
    "          \n",
    "        } else {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "          output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "        }\n",
    "      } else {\n",
    "        date_tracker = c(date_tracker, date)\n",
    "        output_matrix[icount, 14] = days_of_year_table[day_index, 3]\n",
    "        output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "        output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "        output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "      }\n",
    "      \n",
    "      output_matrix[icount, 1] = days_of_year_table[day_index, 4]\n",
    "      output_matrix[icount, 2] = data_matrix[num, 32]\n",
    "      output_matrix[icount, 3] = data_matrix[num, 22]\n",
    "      output_matrix[icount, 4] = data_matrix[num, 36]\n",
    "      output_matrix[icount, 5] = abs(round(data_matrix[num, 35], digits = 2))\n",
    "      output_matrix[icount, 11] = data_matrix[num, 28]\n",
    "      output_matrix[icount, 12] = data_matrix[num, 30]\n",
    "      output_matrix[icount, 13] = data_matrix[num, 12]\n",
    "      output_matrix[icount, 6] = abs(round(data_matrix[num, 10], digits = 2))\n",
    "      \n",
    "      ####Event Type and Iteration####\n",
    "      output_matrix[icount, 10] = event[2]\n",
    "      icount = icount + 1\n",
    "    }\n",
    "    if (is.na(data_matrix[num, 27]) == FALSE){\n",
    "      \n",
    "      # Check the day vector #\n",
    "      if (first_go_around) {\n",
    "        if (day_vector_land[num] == 0) {\n",
    "          day_vector_land = day_vector_land + 1\n",
    "          zero_utc_condition = TRUE\n",
    "          first_go_around = FALSE\n",
    "          \n",
    "        } else {\n",
    "          day_vector_land = day_vector_land\n",
    "          zero_utc_condition = FALSE\n",
    "          first_go_around = FALSE\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      ####Classic Events####\n",
    "      day_index = which(days_of_year_table[, 1] == day_vector_land[num])\n",
    "      date = paste(days_of_year_table[day_index, 4], days_of_year_table[day_index, 5], days_of_year_table[day_index, 3], sep = \"-\")\n",
    "      \n",
    "      if (date %in% date_tracker) {\n",
    "        \n",
    "        # Check the second duplicate onset time value\n",
    "        if (as.numeric(data_matrix[num, 27]) < land_breeze_window_start_time) {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5] + 1\n",
    "          next_day_index = day_index + 1\n",
    "          output_matrix[icount, 8] = mjo_data[next_day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[next_day_index, 7], digits = 2)\n",
    "          output_matrix[icount, 14] = days_of_year_table[next_day_index, 3]\n",
    "          output_matrix[icount - 1, 14] = days_of_year_table[day_index, 3]\n",
    "          \n",
    "        } else {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "          output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "        }\n",
    "      } else {\n",
    "        date_tracker = c(date_tracker, date)\n",
    "        output_matrix[icount, 14] = days_of_year_table[day_index, 3]\n",
    "        output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "        output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "        output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "      }\n",
    "      \n",
    "      output_matrix[icount, 1] = days_of_year_table[day_index, 4]\n",
    "      output_matrix[icount, 2] = data_matrix[num, 27]\n",
    "      output_matrix[icount, 3] = data_matrix[num, 16]\n",
    "      output_matrix[icount, 4] = data_matrix[num, 18]\n",
    "      output_matrix[icount, 5] = abs(round(data_matrix[num, 17], digits = 2))\n",
    "      output_matrix[icount, 11] = 9999\n",
    "      output_matrix[icount, 12] = 9999\n",
    "      output_matrix[icount, 13] = 9999\n",
    "      output_matrix[icount, 6] = 9999\n",
    "      \n",
    "      ####Event Type and Iteration####\n",
    "      output_matrix[icount, 10] = event[1]\n",
    "      icount = icount + 1\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # New conditional statement for duplicate dates with equal onset time and duration\n",
    "  unique_dates = unique(output_matrix[, c(1, 2, 3)])\n",
    "  for (i in 1:nrow(unique_dates)) {\n",
    "    duplicate_rows = which(output_matrix[, 1] == unique_dates[i, 1] & output_matrix[, 2] == unique_dates[i, 2] & output_matrix[, 3] == unique_dates[i, 3])\n",
    "    if (length(duplicate_rows) > 1) {\n",
    "      output_matrix[duplicate_rows[1], 14] = days_of_year_table[which(days_of_year_table[, 1] == unique_dates[i, 1]), 3]\n",
    "      output_matrix = output_matrix[-duplicate_rows[-1], ]\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  large_table = data.frame(\"Year\" = as.numeric(output_matrix[, 14]),\n",
    "                           \"Month\" = as.numeric(output_matrix[, 1]),\n",
    "                           \"Day\" = as.numeric(output_matrix[, 7]),\n",
    "                           \"Onset_time\" = round(as.numeric(output_matrix[, 2]), digits = 2),\n",
    "                           \"Duration\" = round(as.numeric(output_matrix[, 3]), digits = 2),\n",
    "                           \"Time_Max_Speed\" = as.numeric(output_matrix[, 4]),\n",
    "                           \"Max_Speed\" = as.numeric(output_matrix[, 5]),\n",
    "                           \"MJO_Phase\" = as.numeric(output_matrix[, 8]),\n",
    "                           \"MJO_Mag\" = as.numeric(output_matrix[, 9]),\n",
    "                           \"Event_Type\" = output_matrix[, 10],\n",
    "                           \"Flip2_Onset_Time\" = round(as.numeric(output_matrix[, 11]), digits = 2),\n",
    "                           \"Flip2_Duration\" = round(as.numeric(output_matrix[, 12]), digits = 2),\n",
    "                           \"Flip2_Time_Max_speed\" = as.numeric(output_matrix[, 13]),\n",
    "                           \"Flip2_Max_Speed\" = as.numeric(output_matrix[, 6]))\n",
    "  \n",
    "  return(na.omit(large_table))\n",
    "}\n",
    "\n",
    "#####Table Creator Function: Sea#####\n",
    "table_maker_sea = function(data_matrix, local_0UTC_time, sea_breeze_window_start_time){\n",
    "  event = c(\"Classic\", \"Interruption\")\n",
    "  end = dim(data_matrix)[1]\n",
    "  z = seq(1, end, by = 1)\n",
    "  output_matrix = matrix(nrow = length(z), ncol = 14)\n",
    "  icount = 1\n",
    "  first_go_around = TRUE\n",
    "  date_tracker = list()\n",
    "  \n",
    "  for (num in z){\n",
    "    if (is.na(data_matrix[num, 25]) == TRUE & is.na(data_matrix[num, 37]) == TRUE){\n",
    "    }\n",
    "    if (is.na(data_matrix[num, 31]) == FALSE){\n",
    "      \n",
    "      # Check the day vector #\n",
    "      if (first_go_around) {\n",
    "        if (day_vector_sea[num] == 0) {\n",
    "          day_vector_sea = day_vector_sea + 1\n",
    "          zero_utc_condition = TRUE\n",
    "          first_go_around = FALSE\n",
    "          \n",
    "        } else {\n",
    "          day_vector_sea = day_vector_sea\n",
    "          zero_utc_condition = FALSE\n",
    "          first_go_around = FALSE\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      ####Interruption Event####\n",
    "      \n",
    "      day_index = which(days_of_year_table[, 1] == day_vector_sea[num])\n",
    "      date = paste(days_of_year_table[day_index, 4], days_of_year_table[day_index, 5], days_of_year_table[day_index, 3], sep = \"-\")\n",
    "      \n",
    "      if (date %in% date_tracker) {\n",
    "        \n",
    "        # Check the second duplicate onset time value\n",
    "        if (as.numeric(data_matrix[num, 31]) < sea_breeze_window_start_time) {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5] + 1\n",
    "          next_day_index = day_index + 1\n",
    "          output_matrix[icount, 8] = mjo_data[next_day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[next_day_index, 7], digits = 2)\n",
    "          output_matrix[icount, 14] = days_of_year_table[next_day_index, 3]\n",
    "          output_matrix[icount - 1, 14] = days_of_year_table[day_index, 3]\n",
    "          \n",
    "        } else {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "          output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "        }\n",
    "      } else {\n",
    "        date_tracker = c(date_tracker, date)\n",
    "        output_matrix[icount, 14] = days_of_year_table[day_index, 3]\n",
    "        output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "        output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "        output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "      }\n",
    "      \n",
    "      output_matrix[icount, 1] = days_of_year_table[day_index, 4]\n",
    "      output_matrix[icount, 2] = data_matrix[num, 31]\n",
    "      output_matrix[icount, 3] = data_matrix[num, 19]\n",
    "      output_matrix[icount, 4] = data_matrix[num, 34]\n",
    "      output_matrix[icount, 5] = abs(round(data_matrix[num, 33], digits = 2))\n",
    "      output_matrix[icount, 11] = data_matrix[num, 26]\n",
    "      output_matrix[icount, 12] = data_matrix[num, 29]\n",
    "      output_matrix[icount, 13] = data_matrix[num, 11]\n",
    "      output_matrix[icount, 6] = abs(round(data_matrix[num, 8], digits = 2))\n",
    "      \n",
    "      ####Event Type and Iteration####\n",
    "      output_matrix[icount, 10] = event[2]\n",
    "      icount = icount + 1\n",
    "    }\n",
    "    if (is.na(data_matrix[num, 25]) == FALSE){\n",
    "      \n",
    "      # Check the day vector #\n",
    "      if (first_go_around) {\n",
    "        if (day_vector_sea[num] == 0) {\n",
    "          day_vector_sea = day_vector_sea + 1\n",
    "          zero_utc_condition = TRUE\n",
    "          first_go_around = FALSE\n",
    "          \n",
    "        } else {\n",
    "          day_vector_sea = day_vector_sea\n",
    "          zero_utc_condition = FALSE\n",
    "          first_go_around = FALSE\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      day_index = which(days_of_year_table[, 1] == day_vector_sea[num])\n",
    "      date = paste(days_of_year_table[day_index, 4], days_of_year_table[day_index, 5], days_of_year_table[day_index, 3], sep = \"-\")\n",
    "      \n",
    "      if (date %in% date_tracker) {\n",
    "        \n",
    "        # Check the second duplicate onset time value\n",
    "        if (as.numeric(data_matrix[num, 25]) < sea_breeze_window_start_time) {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5] + 1\n",
    "          next_day_index = day_index + 1\n",
    "          output_matrix[icount, 8] = mjo_data[next_day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[next_day_index, 7], digits = 2)\n",
    "          output_matrix[icount, 14] = days_of_year_table[next_day_index, 3]\n",
    "          output_matrix[icount - 1, 14] = days_of_year_table[day_index, 3]\n",
    "          \n",
    "        } else {\n",
    "          output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "          output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "          output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "        }\n",
    "      } else {\n",
    "        date_tracker = c(date_tracker, date)\n",
    "        output_matrix[icount, 14] = days_of_year_table[day_index, 3]\n",
    "        output_matrix[icount, 7] = days_of_year_table[day_index, 5]\n",
    "        output_matrix[icount, 8] = mjo_data[day_index, 6]\n",
    "        output_matrix[icount, 9] = round(mjo_data[day_index, 7], digits = 2)\n",
    "      }\n",
    "      \n",
    "      output_matrix[icount, 1] = days_of_year_table[day_index, 4]\n",
    "      output_matrix[icount, 2] = data_matrix[num, 25]\n",
    "      output_matrix[icount, 3] = data_matrix[num, 13]\n",
    "      output_matrix[icount, 4] = data_matrix[num, 15]\n",
    "      output_matrix[icount, 5] = abs(round(data_matrix[num, 14], digits = 2))\n",
    "      output_matrix[icount, 11] = 9999\n",
    "      output_matrix[icount, 12] = 9999\n",
    "      output_matrix[icount, 13] = 9999\n",
    "      output_matrix[icount, 6] = 9999\n",
    "      \n",
    "      ####Event Type and Iteration####\n",
    "      output_matrix[icount, 10] = event[1]\n",
    "      icount = icount + 1\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # New conditional statement for duplicate dates with equal onset time and duration\n",
    "  unique_dates = unique(output_matrix[, c(1, 2, 3)])\n",
    "  for (i in 1:nrow(unique_dates)) {\n",
    "    duplicate_rows = which(output_matrix[, 1] == unique_dates[i, 1] & output_matrix[, 2] == unique_dates[i, 2] & output_matrix[, 3] == unique_dates[i, 3])\n",
    "    if (length(duplicate_rows) > 1) {\n",
    "      output_matrix[duplicate_rows[1], 14] = days_of_year_table[which(days_of_year_table[, 1] == unique_dates[i, 1]), 3]\n",
    "      output_matrix = output_matrix[-duplicate_rows[-1], ]\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  large_table = data.frame(\"Year\" = as.numeric(output_matrix[, 14]),\n",
    "                           \"Month\" = as.numeric(output_matrix[, 1]),\n",
    "                           \"Day\" = as.numeric(output_matrix[, 7]),\n",
    "                           \"Onset_time\" = round(as.numeric(output_matrix[, 2]), digits = 2),\n",
    "                           \"Duration\" = round(as.numeric(output_matrix[, 3]), digits = 2),\n",
    "                           \"Time_Max_Speed\" = as.numeric(output_matrix[, 4]),\n",
    "                           \"Max_Speed\" = as.numeric(output_matrix[, 5]),\n",
    "                           \"MJO_Phase\" = as.numeric(output_matrix[, 8]),\n",
    "                           \"MJO_Mag\" = as.numeric(output_matrix[, 9]),\n",
    "                           \"Event_Type\" = output_matrix[, 10],\n",
    "                           \"Flip2_Onset_Time\" = round(as.numeric(output_matrix[, 11]), digits = 2),\n",
    "                           \"Flip2_Duration\" = round(as.numeric(output_matrix[, 12]), digits = 2),\n",
    "                           \"Flip2_Time_Max_speed\" = as.numeric(output_matrix[, 13]),\n",
    "                           \"Flip2_Max_Speed\" = as.numeric(output_matrix[, 6]))\n",
    "  \n",
    "  return(na.omit(large_table))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21303106-2649-45db-aaeb-01e839a32819",
   "metadata": {},
   "source": [
    "### Land/Sea Breeze Detection Function (Separation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e739be4-2981-4f4f-bd31-34f001a7d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_sea_breeze_detection_algorithm = function(data_set, time_file, day_file_sea, day_file_land, sampling_frequency){\n",
    "  z = seq(1, length(data_set), by = 1)\n",
    "  timing = matrix(nrow = length(z), ncol = 5)\n",
    "  total_data_matrix = matrix(nrow = length(z), ncol = 37)\n",
    "  day_count_sea = -1\n",
    "  day_count_land = -1\n",
    "  num_count = 0\n",
    "  num_count_land = 0\n",
    "  second_flip_max = rep(NA, 3)\n",
    "  second_flip_max_land = rep(NA, 3)\n",
    "  first_event = 0\n",
    "  end_function = FALSE\n",
    "  for (num in z){\n",
    "    if (end_function == TRUE){\n",
    "      break\n",
    "    }\n",
    "    \n",
    "    if (data_set[num] < 0 && data_set[num + 1] > 0 && data_set[num + (3 * (1 / sampling_frequency))] > 0){\n",
    "      \n",
    "      #Calculate the zero crossing from the index value#\n",
    "      first_zero_crossing_index = zero_crossing(time_1 = z[num],\n",
    "                                                value_t1 = data_set[num],\n",
    "                                                time_2 = z[num+1],\n",
    "                                                value_t2 = data_set[num+1])\n",
    "      \n",
    "      #Convert the zero crossing index to actual time#\n",
    "      first_zero_crossing_time = convert_index_to_time(first_zero_crossing_index, time_file, sampling_frequency)\n",
    "      \n",
    "      #Check for an interruption#\n",
    "      if (day_file_sea[num + 1] == day_count_sea){\n",
    "        timing[num, 2] = first_zero_crossing_time\n",
    "        z.=seq(z[num] + 1, z[num] + (25 * (1 / sampling_frequency)), by = 1)\n",
    "        icount = 1\n",
    "        duration_vector = rep(NA, (25 * (1 / sampling_frequency)))\n",
    "        speed_matrix_2 = matrix(nrow = (25 * (1 / sampling_frequency)), ncol = 2)\n",
    "        for (sea in z.){\n",
    "          if (is.na(data_set[sea]) == TRUE){\n",
    "            end_function = TRUE\n",
    "            break\n",
    "          }\n",
    "          if (data_set[sea] > 0){\n",
    "            duration_vector[icount] = time_file[sea]\n",
    "            speed_matrix_2[icount, 1] = data_set[sea]\n",
    "            speed_matrix_2[icount, 2] = time_file[sea]\n",
    "            end_duration_calc_index = z[sea]\n",
    "            icount = icount + 1\n",
    "          } else {\n",
    "            end_duration_calc_index2 = z[sea - 1]\n",
    "            end_duration_calc_index_plus2 = z[sea]\n",
    "            second_cross_values2 = matrix(nrow = 1, ncol = 1)\n",
    "            second_cross_values2[1, 1] = data_set[sea]\n",
    "            break\n",
    "          }\n",
    "        }\n",
    "        \n",
    "        length_speed_matrix2 = length(na.trim(speed_matrix_2[, 1]))\n",
    "        second_zero_crossing_index2 = zero_crossing(time_1 = end_duration_calc_index2,\n",
    "                                                    value_t1 = speed_matrix_2[length_speed_matrix2, 1],\n",
    "                                                    time_2 = end_duration_calc_index_plus2,\n",
    "                                                    value_t2 = second_cross_values2[1, 1])\n",
    "        \n",
    "        total_data_matrix[num, 7] = length(na.omit(duration_vector)) - 1 + (z[num + 1] - first_zero_crossing_index) + -1 *(end_duration_calc_index2 - second_zero_crossing_index2)\n",
    "        second_flip_max[3] = length(na.omit(duration_vector)) -1 + (z[num + 1] - first_zero_crossing_index) + -1 *(end_duration_calc_index2 - second_zero_crossing_index2)\n",
    "        total_data_matrix[num, 8] = max(na.omit(speed_matrix_2[, 1]))\n",
    "        second_flip_max[1] = max(na.omit(speed_matrix_2[, 1]))\n",
    "        \n",
    "        speed_matrix_2[is.na(speed_matrix_2)] = -9999\n",
    "        \n",
    "        for (count in 1:(25 * (1 / sampling_frequency))){\n",
    "          if (speed_matrix_2[count, 1] == max(na.omit(speed_matrix_2[, 1]))) {\n",
    "            total_data_matrix[num, 11] = speed_matrix_2[count, 2]\n",
    "            second_flip_max[2] = speed_matrix_2[count, 2]\n",
    "          } else {\n",
    "            next\n",
    "          }\n",
    "        }\n",
    "        num_count = -1\n",
    "        total_data_matrix[num, 26] = timing[num, 2]\n",
    "        total_data_matrix[num, 29] = second_flip_max[3]\n",
    "        total_data_matrix[num, 19] = space_vector[1]\n",
    "        total_data_matrix[num, 31] = space_vector[4]\n",
    "        total_data_matrix[num, 33] = space_vector[2]\n",
    "        total_data_matrix[num, 34] = space_vector[3]\n",
    "        \n",
    "        if (second_flip_max[1] >= space_vector[2]){\n",
    "          total_data_matrix[num, 21] = second_flip_max[2]\n",
    "          total_data_matrix[num, 20] = second_flip_max[1]\n",
    "        } else {\n",
    "          total_data_matrix[num, 21] = space_vector[3]\n",
    "          total_data_matrix[num, 20] = space_vector[2]\n",
    "        }\n",
    "      } else {\n",
    "        if (num_count > 0){\n",
    "          total_data_matrix[num_count, 13] = space_vector[1]\n",
    "          total_data_matrix[num_count, 14] = space_vector[2]\n",
    "          total_data_matrix[num_count, 15] = space_vector[3]\n",
    "          total_data_matrix[num_count, 25] = space_vector[4]\n",
    "        }\n",
    "        timing[num, 1] = first_zero_crossing_time\n",
    "        day_count_sea[1] = day_file_sea[num + 1]\n",
    "        z.= seq(z[num] + 1, z[num] + (25 * (1 / sampling_frequency)), by = 1)\n",
    "        icount = 1\n",
    "        duration_vector = rep(NA, (25 * (1 / sampling_frequency)))\n",
    "        speed_matrix = matrix(nrow = (25 * (1 / sampling_frequency)), ncol = 2)\n",
    "        for (sea in z.){\n",
    "          if (is.na(data_set[sea]) == TRUE){\n",
    "            end_function = TRUE\n",
    "            break\n",
    "          }\n",
    "          if (data_set[sea] > 0){\n",
    "            duration_vector[icount] = time_file[sea]\n",
    "            speed_matrix[icount, 1] = data_set[sea]\n",
    "            speed_matrix[icount, 2] = time_file[sea]\n",
    "            icount = icount + 1\n",
    "          } else {\n",
    "            end_duration_calc_index = z[sea - 1]\n",
    "            end_duration_calc_index_plus = z[sea]\n",
    "            second_cross_values = matrix(nrow = 1, ncol = 1)\n",
    "            second_cross_values[1, 1] = data_set[sea]\n",
    "            break\n",
    "          }\n",
    "        }\n",
    "        \n",
    "        length_speed_matrix = length(na.trim(speed_matrix[, 1]))\n",
    "        second_zero_crossing_index = zero_crossing(time_1 = end_duration_calc_index,\n",
    "                                                   value_t1 = speed_matrix[length_speed_matrix, 1],\n",
    "                                                   time_2 = end_duration_calc_index_plus,\n",
    "                                                   value_t2 = second_cross_values[1, 1])\n",
    "        total_data_matrix[num, 1] = length(na.omit(duration_vector)) - 1 + (z[num + 1] - first_zero_crossing_index) + -1 *(end_duration_calc_index-second_zero_crossing_index)\n",
    "        total_data_matrix[num, 2] = max(na.omit(speed_matrix[, 1]))\n",
    "        \n",
    "        speed_matrix[is.na(speed_matrix)] = -9999\n",
    "        \n",
    "        for (count in 1:(25 * (1 / sampling_frequency))){\n",
    "          if (speed_matrix[count, 1] == max(speed_matrix[, 1])) {\n",
    "            total_data_matrix[num, 5] = speed_matrix[count, 2]\n",
    "          } else {\n",
    "            next\n",
    "          }\n",
    "        }\n",
    "        space_vector = rep(NA, 4)\n",
    "        space_vector[1] = total_data_matrix[num, 1]\n",
    "        space_vector[2] = total_data_matrix[num, 2]\n",
    "        space_vector[3] = total_data_matrix[num, 5]\n",
    "        space_vector[4] = timing[num, 1]\n",
    "        num_count = z[num]\n",
    "        \n",
    "        if (first_event == 0){\n",
    "          total_data_matrix[num_count, 13] = space_vector[1]\n",
    "          total_data_matrix[num_count, 14] = space_vector[2]\n",
    "          total_data_matrix[num_count, 15] = space_vector[3]\n",
    "          total_data_matrix[num_count, 25] = space_vector[4]\n",
    "          first_event = 12\n",
    "        }\n",
    "      }\n",
    "    } else {\n",
    "      if (data_set[num] > 0 && data_set[num + 1] < 0 && data_set[num + (3 * (1 / sampling_frequency))] < 0){\n",
    "        \n",
    "        #Calculate the zero crossing from the index value#\n",
    "        first_zero_crossing_index_land= zero_crossing(time_1 = z[num],\n",
    "                                                      value_t1 = data_set[num],\n",
    "                                                      time_2 = z[num + 1],\n",
    "                                                      value_t2 = data_set[num + 1])\n",
    "        \n",
    "        #Convert the zero crossing index to actual time#\n",
    "        first_zero_crossing_time_land= convert_index_to_time(first_zero_crossing_index_land, time_file, sampling_frequency)\n",
    "        \n",
    "        #Check for an interruption event#\n",
    "        if (day_file_land[num + 1] == day_count_land){\n",
    "          timing[num, 4] = first_zero_crossing_time_land\n",
    "          jcount = 1\n",
    "          duration_vector = rep(NA, (25 * (1 / sampling_frequency)))\n",
    "          speed_matrix = matrix(nrow = (25 * (1 / sampling_frequency)), ncol = 2)\n",
    "          z.. = seq(z[num] + 1, z[num] + (25 * (1 / sampling_frequency)), by = 1)\n",
    "          for (land in z..){\n",
    "            if (is.na(data_set[land]) == TRUE){\n",
    "              end_function = TRUE\n",
    "              break\n",
    "            }\n",
    "            if (data_set[land] < 0){\n",
    "              duration_vector[jcount] = time_file[land]\n",
    "              speed_matrix[jcount, 1] = data_set[land]\n",
    "              speed_matrix[jcount, 2] = time_file[land]\n",
    "              jcount = jcount + 1\n",
    "            } else {\n",
    "              end_duration_calc_index_land = z[land - 1]\n",
    "              end_duration_calc_index_plus_land = z[land]\n",
    "              second_cross_values_land = matrix(nrow = 1, ncol = 1)\n",
    "              second_cross_values_land[1, 1] = data_set[land]\n",
    "              break\n",
    "            }\n",
    "          }\n",
    "          \n",
    "          length_speed_matrix_land = length(na.trim(speed_matrix[, 1]))\n",
    "          second_zero_crossing_land_index = zero_crossing(time_1 = end_duration_calc_index_land,\n",
    "                                                          value_t1 = speed_matrix[length_speed_matrix_land, 1],\n",
    "                                                          time_2 = end_duration_calc_index_plus_land,\n",
    "                                                          value_t2 = second_cross_values_land[1, 1])\n",
    "          \n",
    "          total_data_matrix[num, 9] = length(na.omit(duration_vector)) - 1 + (z[num + 1] - first_zero_crossing_index_land) + -1 *(end_duration_calc_index_land-second_zero_crossing_land_index)\n",
    "          second_flip_max_land[3] = length(na.omit(duration_vector)) - 1 + (z[num + 1] - first_zero_crossing_index_land) + -1 *(end_duration_calc_index_land-second_zero_crossing_land_index)\n",
    "          total_data_matrix[num, 10] = min(na.omit(speed_matrix[, 1]))\n",
    "          second_flip_max_land[1] = min(na.omit(speed_matrix[, 1]))\n",
    "          \n",
    "          speed_matrix[is.na(speed_matrix)] = 9999\n",
    "          \n",
    "          for (count in 1:(25 * (1 / sampling_frequency))){\n",
    "            if (speed_matrix[count, 1] == min(na.omit(speed_matrix[, 1]))){\n",
    "              total_data_matrix[num, 12] = speed_matrix[count, 2]\n",
    "              second_flip_max_land[2] = speed_matrix[count, 2]\n",
    "            } else {\n",
    "              next\n",
    "            }\n",
    "          }\n",
    "          num_count_land = -1\n",
    "          total_data_matrix[num, 28] = timing[num, 4]\n",
    "          total_data_matrix[num, 30] = second_flip_max_land[3]\n",
    "          total_data_matrix[num, 22] = space_vector_land[1]\n",
    "          total_data_matrix[num, 32] = space_vector_land[4]\n",
    "          total_data_matrix[num, 35] = space_vector_land[2]\n",
    "          total_data_matrix[num, 36] = space_vector_land[3]\n",
    "          if (second_flip_max_land[1] <= space_vector_land[2]){\n",
    "            total_data_matrix[num, 24] = second_flip_max_land[2]\n",
    "            total_data_matrix[num, 23] = second_flip_max_land[1]\n",
    "          } else {\n",
    "            total_data_matrix[num, 24] = space_vector_land[3]\n",
    "            total_data_matrix[num, 23] = space_vector_land[2]\n",
    "          }\n",
    "        } else {\n",
    "          if (num_count_land > 0){\n",
    "            total_data_matrix[num_count_land, 16] = space_vector_land[1]\n",
    "            total_data_matrix[num_count_land, 17] = space_vector_land[2]\n",
    "            total_data_matrix[num_count_land, 18] = space_vector_land[3]\n",
    "            total_data_matrix[num_count_land, 27] = space_vector_land[4]\n",
    "          }\n",
    "          timing[num, 3] = first_zero_crossing_time_land\n",
    "          day_count_land[1] = day_file_land[num+1]\n",
    "          jcount = 1\n",
    "          duration_vector = rep(NA, (25 * (1 / sampling_frequency)))\n",
    "          speed_matrix = matrix(nrow = (25 * (1 / sampling_frequency)), ncol = 2)\n",
    "          z..= seq(z[num] + 1, z[num] + (25 * (1 / sampling_frequency)), by = 1)\n",
    "          for (land in z..){\n",
    "            if (is.na(data_set[land]) == TRUE){\n",
    "              end_function = TRUE\n",
    "              total_data_matrix[num_count, 13] = space_vector[1]\n",
    "              total_data_matrix[num_count, 14] = space_vector[2]\n",
    "              total_data_matrix[num_count, 15] = space_vector[3]\n",
    "              total_data_matrix[num_count, 25] = space_vector[4]\n",
    "              break\n",
    "            }\n",
    "            if (data_set[land] < 0){\n",
    "              duration_vector[jcount] = time_file[land]\n",
    "              speed_matrix[jcount, 1] = data_set[land]\n",
    "              speed_matrix[jcount, 2] = time_file[land]\n",
    "              jcount = jcount + 1\n",
    "            } else {\n",
    "              end_duration_calc_index_land  = z[land - 1]\n",
    "              end_duration_calc_index_plus_land = z[land]\n",
    "              second_cross_values_land = matrix(nrow = 1, ncol = 1)\n",
    "              second_cross_values_land[1, 1] = data_set[land]\n",
    "              break\n",
    "            }\n",
    "          }\n",
    "          \n",
    "          length_speed_matrix_land = length(na.trim(speed_matrix[, 1]))\n",
    "          second_zero_crossing_land_index = zero_crossing(time_1 = end_duration_calc_index_land,\n",
    "                                                          value_t1 = speed_matrix[length_speed_matrix_land, 1],\n",
    "                                                          time_2 = end_duration_calc_index_plus_land,\n",
    "                                                          value_t2 = second_cross_values_land[1, 1])\n",
    "          total_data_matrix[num, 3] =length(na.omit(duration_vector)) - 1 + (z[num+1]-first_zero_crossing_index_land) + -1 *(end_duration_calc_index_land-second_zero_crossing_land_index)\n",
    "          total_data_matrix[num, 4] = min(na.omit(speed_matrix[, 1]))\n",
    "          \n",
    "          \n",
    "          speed_matrix[is.na(speed_matrix)] = 9999\n",
    "          \n",
    "          for (count in 1:(25 * (1 / sampling_frequency))){\n",
    "            if (speed_matrix[count, 1] == min(na.omit(speed_matrix[,1]))){\n",
    "              total_data_matrix[num, 6] = speed_matrix[count, 2]\n",
    "            } else {\n",
    "              next\n",
    "            }\n",
    "          }\n",
    "          space_vector_land = rep(NA, 3)\n",
    "          space_vector_land[1] = total_data_matrix[num, 3]\n",
    "          space_vector_land[2] = total_data_matrix[num, 4]\n",
    "          space_vector_land[3] = total_data_matrix[num, 6]\n",
    "          space_vector_land[4] = timing[num, 3]\n",
    "          num_count_land = z[num]\n",
    "        }\n",
    "      } else {\n",
    "        timing[num, 5] = 9999\n",
    "        total_data_matrix[num, 37] = 9999\n",
    "      }\n",
    "    }}\n",
    "  return(total_data_matrix)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dedcf3-bdfd-48d8-a635-ac0ae1eb9c5d",
   "metadata": {},
   "source": [
    "## Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ebe26-bb06-42ca-a5f0-2b3f067f967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Time Variables#####\n",
    "num_days = calculate_num_days(data_start_date, data_end_date)\n",
    "timefile = create_time_vector(local_zero_utc, num_days, sampling_rate)\n",
    "days_of_year_table = create_days_of_year_table(data_start_date, data_end_date)\n",
    "\n",
    "######Land Breeze Day Vector######\n",
    "day_vector_land = generate_day_vector(local_zero_utc, land_breeze_window_start_time, sampling_rate, num_days)\n",
    "\n",
    "######Sea Breeze Day Vector Definition######\n",
    "day_vector_sea = generate_day_vector(local_zero_utc, sea_breeze_window_start_time, sampling_rate, num_days)\n",
    "\n",
    "######MJO Data######\n",
    "mjo_data = filter_mjo_data(MJO_RMM_file_location, data_start_date, data_end_date)\n",
    "\n",
    "####Import Data####\n",
    "setwd(data_file_path)\n",
    "\n",
    "# List files based on the specified file type *\n",
    "file_list = list.files(pattern = paste0(\"*.\", file_type))\n",
    "\n",
    "# Read contents of data file #\n",
    "file = nc_open(file_list)\n",
    "u_comp = ncvar_get(file, u_comp_name)\n",
    "v_comp = ncvar_get(file, v_comp_name)\n",
    "nc_long = ncvar_get(file, \"longitude\")\n",
    "nc_lat = ncvar_get(file, \"latitude\")\n",
    "nc_close(file)\n",
    "\n",
    "# Find the indices of the closest latitude and longitude\n",
    "lat_index = which.min(abs(nc_lat - lat_interest))\n",
    "lon_index = which.min(abs(nc_long - lon_interest))\n",
    "\n",
    "# Remove the data for the selected grid point\n",
    "u.slice = u_comp[lon_index, lat_index, ]\n",
    "v.slice = v_comp[lon_index, lat_index, ]\n",
    "\n",
    "#####Convert from components to DD and FF#####\n",
    "wind_speed = sqrt(u.slice^2 + v.slice^2)\n",
    "wind_dir = 180 + (180 / pi) * atan2(u.slice, v.slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c9b34-e25b-4c60-bfd0-e5f9d32e3025",
   "metadata": {},
   "source": [
    "## Grid Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb689eb1-8b5e-4dab-8c6e-1bc1dbb766b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Rotation Angle Determination#####\n",
    "if (is.numeric(coordinate_axis_rotation_user)) {\n",
    "  coordinate_axis_rotation = round(coordinate_axis_rotation_user, digits = 2)\n",
    "  print(paste(\"The user-specified rotation angle is\", coordinate_axis_rotation, \"degrees.\"))\n",
    "} else {\n",
    "  coordinate_axis_rotation = round(cablculate_angle_from_x_axis(lat1, lon1, lat2, lon2, lat3, lon3), digits = 2)\n",
    "  print(paste(\"The calculated rotation angle is\", coordinate_axis_rotation, \"degrees.\"))\n",
    "}\n",
    "\n",
    "#####Rotate the Axis and Calculate the u and v components#####\n",
    "u.rot_obs = -wind_speed * sin((pi / 180) * (wind_dir + coordinate_axis_rotation))\n",
    "v.rot_obs = -wind_speed * cos((pi / 180) * (wind_dir + coordinate_axis_rotation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3741b2-b7c7-472a-b52b-d36b9985f638",
   "metadata": {},
   "source": [
    "## Filtering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03e0ab-06e5-4286-beb8-6737619e125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Apply the 3-day Chebyshev Type I#####\n",
    "low_pass_filter_results = pass.filt(u.rot_obs, W = (1 / (synoptic_filter_period * (24 * (1 / sampling_rate)))),type = \"low\",method = \"ChebyshevI\")\n",
    "\n",
    "#####Subtract the Filter from Shore-Perpendicular Wind#####\n",
    "no_synoptic_winds = u.rot_obs-low_pass_filter_results\n",
    "filtered_winds_final = pass.filt(no_synoptic_winds, W = (1 / (noise_filter_period * (1 / sampling_rate))), type = \"low\", method = \"ChebyshevI\")\n",
    "\n",
    "#####Run the Function#####\n",
    "results_filtering_algorithm = land_sea_breeze_detection_algorithm(filtered_winds_final, timefile, day_vector_sea, day_vector_land, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6219b-01b5-4209-9920-001165361111",
   "metadata": {},
   "source": [
    "## Data Table Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c1992-bf06-4529-a9b9-b7bce450c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Table Creation#####\n",
    "output_data_table_land = table_maker_land(results_filtering_algorithm, local_zero_utc, land_breeze_window_start_time)\n",
    "output_data_table_sea = table_maker_sea(results_filtering_algorithm,local_zero_utc, sea_breeze_window_start_time)\n",
    "\n",
    "#####Table Export######\n",
    "setwd(data_table_output_directory)\n",
    "write.csv(output_data_table_land, file = output_file_name_land, row.names = T)\n",
    "write.csv(output_data_table_sea, file = output_file_name_sea, row.names = T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
